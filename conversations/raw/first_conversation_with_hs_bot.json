[
    {
        "content": "You are a chatbot whose responsibility is presenting a machine learning (ML) paper on predicting valvular heart disease and\nmurmurs from heart-sounds. I am the programmer, and I will sometimes referr to myself as `System`.\n\nStart the conversation by greeting the user, informing them of your purpose, and asking where they would like to start.\nKeep your responses brief and concise; no longer than 5 sentences.\n\n# Abstract #\nObjective: To assess the ability of state-of-the-art machine learning algorithms to detect valvular heart disease (VHD)\nfrom heart sound (HS) recordings in a general population that includes asymptomatic cases and intermediate stages of\ndisease progression.\n\nMethods: Using heart sound (HS) recordings (from 4 auscultation positions) annotated with murmur grade from 2124\nparticipants from the Troms\u00f8 7 study, we trained a recurrent neural network (RNN) to detect and grade murmurs and\nsubsequently predict presence of VHD.\n\nResults: Presence of aortic stenosis (AS) was detected with sensitivity 90.9%, specificity 94.5%, and\narea-under-the-curve (AUC) 0.979 (CI:0.963-0.995). At least moderate AS was detected with AUC 0.993 (CI:0.989-0.997).\nModerate or greater aortic and mitral regurgitation (AR and MR) were predicted with AUC 0.634 (CI:0.565-703) and 0.549\n(CI:0.506-0.593) respectively, which increased to 0.766 and 0.677 when adding clinical variables as predictors. Treating\nasymptomatic disease as negative cases increased sensitivity to AR from 54.9% to 85.7%, and sensitivity to MR from 55.6%\nto 83.3%. Screening jointly for at least moderate regurgitation or presence of stenosis resulted in detection of 54.1%\nof positive cases, 60.5% of negative cases, 97.7% of AS cases (n=44), and all 12 MS cases.\n\n# Notation #\nAVPG: aortic valve pressure gradient\n\n# Knowledge Request #\nYou can request information - a `knowledge request` - that is nessecary for assisting the user with commands of the form\n`\u00a4:request_knowledge{hs-paper/<id>}:\u00a4`. When you do this, I will insert the requested information into the conversation (as\n`\"System\"`) so that you can convey it to the user. For example:\n\n    User: What method did the authors use for creating confidence intervals?\n\n    Assistant: \u00a4:request_knowledge{hs-paper/methods_statistical_analysis}:\u00a4\n\n    system: <text describing statistical methods employed>\n\n    Assistant: They used ...\n\nNEVER type `Assistant:` in your responses - I am responsible for prepending roles to messages. ONLY convey information\ncontained in this prompt or that you have requested using `\u00a4:request_knowledge{<id>}:\u00a4` (i.e. information provided by\n`System`). Basically, pretend *you know nothing outside of the information that I give you*.\n\nHere are the knowledge requests you can call upon along with descriptions of their content:\n* `Introduction_the_problem`:\n  1. Prevalence and consequences of VHD\n  2. Burden on healthcare\n  3. Limitations of auscultation, Point-of-care ultrasound, and echocardiogram as screening tools\n* `Introduction_machine_learning_and_heartsounds`:\n  1. Advantages of deep learning for VHD screening\n  2. Limitations of current knowledge\n  4. Why impressive ML results may not reflect true performance\n  5. Primary aims of the study\n* `methods_study_design`:\n  1. Type of data collected\n  2. Data collection methods\n  2. Brief description of study cohort\n* `methods_heart_sound_recording`:\n  1. Technical details on recording of heart-sounds\n* `methods_heart_sound_annotation`:\n  1. Motivation for the choice of training targets and the prediction scheme\n  2. Details on how the heartsounds were annotated\n  3. Details on murmur-grading\n  4. Treatment of corrupt audio\n  5. Treatment of noisy audio\n  6. Count of audio files (total, noisy, corrupted, annotated, etc...)\n  7. How annotations were aggragated into a single label\n* `methods_echocardiography`:\n  1. Technical details on data collection and grading of disease severity\n* `methods_algorithm_developement`:\n  1. How recordings from different auscultation positions entered training\n  2. Programming language and ML library employed\n  3. Model and data processing - motivation and description\n  4. Balancing the dataset\n  5. Training parameters\n  6. audio processing\n  7. Audio segmentation (overview)\n  8. Feature extraction\n* `methods_predicting_AS_using_multiple_auscultation_position`:\n  1. Describes a `multi-position model` that aggragates murmur-predictions across multiple auscultation positions using\n     multivariate linear regression in order to predict the AVPG and AS. The murmur-predictions are generated with the\n     murmur-detection RNN model\n  2. Method and motivation for model selection procedure\n  3. How `multi-position model` model was tested\n* `methods_performance_estimation_and_model_comparison`:\n  1. Motivation for cross-validation\n  2. Steps taken to avoid overfitting and ensure the generalizability of results\n  3. Splitting of the dataset\n* `methods_statistical_analysis`:\n  1. Performance metrics\n  2. Statistical tests and confidence intervals\n  3. Decision threshold selection\n  4. Interrater agreement\n* `results_murmur_prevalence_and_annotator_agreement`:\n  1. Metrics on intrarater agreement\n  2. Murmur prevalence according per rater and position\n  3. Innocent murmur prevalence\n  4. Systolic and diastolic murmurs\n  5. Overlap between AS and MR\n  6. AS prevalence\n* `results_murmur_detection_algorithm_performance`:\n  1. Performance metrics for murmur-prediction\n* `results_VHD_prediction_using_the_murmur_detection_algorithm`:\n  1. Evaluating the heart sound algorithm for detection of each VHD separately for various disease thresholds\n  2. Comparison between ability to detect symptomatic and asymptomatic cases\n  3. Evaluating the multi-position model for AS detection\n* `results_joint_screening_for_clinically_relevant_cases`\n  1. Evaluation of ability to detect presence of any VHD\n  2. Method for predicting presence of any VHD\n* `results_multi_position_prediction_of_aortic_valve_mean_ressure_gradient`\n  1. Parameter estimates for multi-position model\n  2. Comparison between multi-position model and prediction using models that use a fixed position for prediction\n  3. Comparing the multi-position model to models that predict using audio from a fixed position\n* `results_VHD_prediction_using_multiple_predictors`:\n  1. Evaluation of multivariate regression models that predict VHD using both heart sounds and clinical variables\n* `discussion_AS_prediction_was_biggest_success`:\n  1. Can systolic murmurs be attributed to MR or AS?\n  2. Benefits of multi-position model\n  3. AS detectability in relation to disease severity\n  4. Significance of contribution from each position\n* `discussion_comparison_with_cardiologists`:\n  1. Compares performance against cardiologists in Jaffe et al.\n* `discussion_comparison_with_jaffe_study`:\n  1. Compares prediction of murmur, AS, and MR against similar study by Jaffe et al.\n  2. Factors making comparison difficult\n  3. Reasons why our algorithm predicted AS and murmurs more accurately\n  4. Why they predicted MR more accurately\n  5. Intrarater agreement for murmur-annotations\n* `discussion_healthcare_implications`:\n  1. Why early detection of AS matters\n  2. Prevalence of undiagnosed AS\n  3. How many AS-cases could be detected if algorithm was deployed\n  4. Benefit of murmur-detection in healthy middle-aged men\n* `discussion_study_strength_and_limitations`:\n  1. Algorithm does not rate audio quality or detect noise\n  2. Lack of statistical power and risk of overfitting\n  3. Data may not be representative of rushed clinical setting\n  5. Model is fast and unlikely to overfit\n  6. Dataset is unbiased, contains clinical variables, and audio from 4 locations\n  7. High quality annotation\n* `conclusions`:\n  1. AS detected with state of the art performance\n  2. Using audio from multiple positions improved prediction of the AVPG\n  3. Detection of AR and MR was related to presence of symptoms\n  4. Automated HS-analysis can be a cost-effective screening tool",
        "role": "system"
    },
    {
        "content": "Due to the challenges posed by the low number of VHD cases in the study cohort, our approach involved training a deep learning model to predict murmur grade, which would then serve as a proxy target for predicting VHD. A comparison between models trained on VHD and murmur grade can be found in the Supplementary Materials.\n\nThe heart sound recordings were annotated by two General Practitioners (GPs), AD and SA, who were both involved in PhD projects related to heart sounds. AD is a GP specialist with two years of training in cardiology. Before annotation, these two GPs, along with a professor of cardiology (HS) and a professor of General practice (HM), independently annotated 400 recordings. They discussed any disagreements and reached a consensus on the presence and quality of murmurs. This training process continued at intervals throughout the annotation process, where disagreements were discussed to achieve a consensus on the presence of murmurs. The consensus outcomes, to which HM and HS also contributed, are not discussed in this paper. The annotators reviewed spectrogram visualizations of the recordings using Adobe Audition CS6 while classifying the heart sounds. Importantly, they were unaware of the echocardiography results and other information about the study participants during the heart sound annotation.\n\nEach recording was categorized as either normal, systolic murmur, diastolic murmur, or noise (indicating inability to determine the presence of a murmur due to interference or low quality). Any perceived murmurs were graded on a scale from 1 (faint) to 6 (distinct), referencing the Levine scale, commonly used in clinical practice. However, grades 4-6 on this scale are associated with a palpable thrill, which is not directly transferable to recordings. In the annotated set, grades higher than 3 only reflect increases in murmur loudness, not other aspects associated with the Levine scale. In total, 2,129 participants were annotated with both murmur grade and VHD grade. Five were removed due to corrupted audio files, resulting in an effective sample of 2,124 participants and 8,496 annotated audio files (equivalent to 1,416 minutes of audio). The algorithm was trained only on recordings for which both annotators agreed they were not noisy (hereafter referred to as non-noisy recordings). There were 129 (6.1%), 113 (5.3%), 60 (2.8%), and 150 (7.1%) noisy recordings in positions 1 to 4, respectively. 1.4% of participants had noise in all four recordings, and they were excluded from the analysis. For single-recording based prediction, only non-noisy recordings were used. In the case of predictions based on several recordings, noisy recordings were assigned grade 0 (indicating the absence of a murmur).\n\nTo represent the murmur grade of each position, we used the average of the two annotators' gradings. In the following, this variable is referred to simply as murmur grade. By this convention, the dataset contained 465, 280, 303, and 196 cases of murmur grade > 0 in positions 1-4, respectively, and a total of 1,244 audio recordings for which at least one annotator perceived a murmur.",
        "role": "system"
    },
    {
        "content": "All echocardiogram examinations were conducted in accordance with the American Society of Echocardiography's Guidelines, utilizing a GE Vivid E9 ultrasound scanner from GE Medical in Horten, Norway. These examinations were carried out by an experienced echo technician before the heart sounds were annotated. The results were then reviewed by an experienced physician, MS.\n\nThe severity of Aortic Stenosis (AS) and Mitral Stenosis (MS) was graded on a scale of 0 to 3, which included categories for absent, mild, moderate, and severe. Aortic Regurgitation (AR) and Mitral Regurgitation (MR) severity were assessed on a scale of 0 to 4, which included categories for absent, trace, mild, moderate, and severe.\n\nAS severity was determined using the aortic valve mean pressure gradient (AVPGmean) with cutoff values at 15 mm Hg (indicating mild AS), 20 mm Hg (moderate AS), and 40 mm Hg (severe AS).",
        "role": "system"
    },
    {
        "content": "The murmur detection algorithm was trained using HS recordings from all four auscultation positions indiscriminately. Network training and prediction was performed in Matlab using the Matlab deep learning toolbox. The model and data processing used in this study are based on a study by Latif et al., in which state of the art results were achieved for detecting abnormal heart sounds on the physionet 2016 challenge dataset. For network architecture we used a 2-layer (50 neurons each) long-short-term-memory (LSTM) network, followed by a fully connected layer consisting of 30 neurons (Figure S1 shows the model architecture) which finally connects to a regression layer which predicts murmur-grade. See the Supplementary Materials for a performance comparison between models trained using binary and continuous labels respectively. The initial learning rate was set to 0.002, and was halved every 5 epochs. To balance the ratio of murmur to non-murmur samples, we dichotomized the data into murmur-grade\u22651 and murmur-grade<1, and resampled until the ratio between these classes was approximately one-to-one.\n\nAfter performing spike removal (following the steps outlined in a 2009 paper by Schmidt et. al.30) and downsampling the signal to sampling rate of 2205 Hz, each recording was segmented into 6 overlapping (50%) blocks, each consisting of 4 cardiac cycles (each cycle starting and ending at the start of the first heart sound, S1). Detection of cardiac cycle boundaries was achieved using a modified version of the segmentation algorithm of Springer et al31,32 that utilizes information from multiple recordings in order to obtain a more robust heart-rate estimate (detailed descriptions of the modifications can be found in the Supplementary Materials). For each segment, the 13 first Mel frequency cepstral coefficients (MFCC) were computed, where we used the Hanning window function with step size of 25 ms and window overlap of 10 ms for computation of the spectrogram. The input units to the LSTM network were finally obtained by resizing the MFCC matrix to dimensions 13\u00d7200 using cubic interpolation, followed by subtracting the mean and dividing by the standard deviation of the matrix. The median of the predicted murmur-grades of the 6 blocks was used to represent the prediction for the whole audio recording. Figure S2 provides a schematic overview of the steps that convert raw audio input to algorithm prediction.\n",
        "role": "system"
    },
    {
        "content": "Due to the small number of clinically relevant cases of VHD in the dataset, we opted to rely primarily on 8-fold cross validation (CV) to estimate model performance. Extensive use of CV for model selection can result in overestimation of model performance. Prior to performing any data analysis, we therefore set aside a holdout set containing data from 212 (~10% of the data) participants which contains a total of 91 cases (at the audio level) of murmur-grade\u22651, and 55 cases murmur-grade\u22652. Decisions relating to model development were made only to improve prediction of murmur-grade, not prediction of VHD. Finally, most decisions concerning model architecture and data processing  were based on a previous study21, thus minimizing over-fitting as a result of fine tuning the model to the development set. After the models were developed and results had been obtained, we retrained the murmur-detection algorithm using the whole development set and tested for potential over-fitting on the holdout set.",
        "role": "system"
    },
    {
        "content": "We hypothesized that more accurate prediction could be achieved by aggregating murmur-grade predictions from all four recordings in a linear multivariate predictive model, rather than predicting AS using audio from a single predetermined position. In the following, these models are referred to as the multi-position model and single-position models respectively. As there were only 45 cases of mild or greater AS in the development set, using AS classification accuracy for model selection would likely result in overfitting. Therefore, we first model AVPGmean using linear regression, and subsequently use the fitted model to predict AS (without re-estimating the parameters). As model candidates, we considered linear regression models that contained up to 2nd degree terms, and also noise indicator terms (which take values 0 and 1) that effectively adjusts the weights of the non-noisy positions when one or more positions have noisy recordings. Model selection was performed by starting with a base model with one term for each murmur-grade prediction, and then terms with low p-values were stepwise added or eliminated (if p>0.05) in order to find the sub model with the lowest bayesian information criterion (BIC) value; a measure of goodness of fit that penalizes high model complexity. After the best model had been estimated by this procedure, we added, in a similar manner, the noise indicator terms.\n\nTo test if using all four recordings improved prediction of AVPGmean, we computed the AUC for prediction of AVPGmean>u across a range of thresholds (u=7 mm Hg to u=30 mm Hg) using the multiple-position model and each of the single-position models. For comparison against the i\u2019th single-position model (the model that utilizes audio from position i to make predictions) we excluded observations with noise in the i\u2019th position.",
        "role": "system"
    },
    {
        "content": "Conversation summary: The user questioned the methods of a Machine Learning (ML) study on predicting valvular heart disease (VHD). The study involved two General Practitioners (GPs) who classified and graded heart sound recordings from 2,124 participants. They graded aortic stenosis using the aortic valve mean pressure gradient (AVPGmean) with a scale of 0 to 3. The algorithm was trained using LSTM network on heart sound recordings from four auscultation positions, and involved a holdout set for external validation. For predicting Aortic Stenosis (AS), a 'multi-position model' was used that aggregated predicted murmur grades from all four positions. The best model was determined through the lowest Bayesian Information Criterion (BIC) value.",
        "role": "system"
    },
    {
        "content": "The murmur-detection algorithm's ability to predict clinically relevant VHD is summarized in Table 2, which shows the AUC for predicting each disease for different disease cutoff values. Figure S4 shows ROC curves for algorithm prediction of each VHD. Moderate to severe AR was not reliably detected by the algorithm, regardless of which position was used, with AUC values ranging from 0.576 (mitral position) to 0.634 (using predicted max murmur-grade as predictor). Symptomatic AR however, defined herein as presence of angina or dyspnea while resting or walking on flat ground, was significantly more prevalent in the detected cases than in the missed cases; 16.7% and 1.7% of cases respectively (p=0.02). When the positive class was defined to only include symptomatic AR, sensitivity increased from 54.9% (\u00b18.7%) to 83.3% (\u00b121.1%; 12 cases in total, all of which were severe).\n\nMR was the least detected disease, as moderate to severe MR was predicted with an AUC of only 0.558 (CI:0.506-0.593; mitral recording). No consistent trends with regards to which position was most predictive of MR were observed. As was the case for AR, detectability of MR was highly influenced by the presence of symptoms. Symptomatic MR, defined the same way as it was for AR, was significantly more prevalent in the detected cases than in the missed cases; 12.9% and 4.5% of cases respectively (p=0.02). The algorithm detected 22 out of 27 (81.5% \u00b115.9%) symptomatic cases of moderate to severe MR, which is a considerable increase in detection rate relative to 55.6% (\u00b16.3%) when asymptomatic cases were included.\n\nPresence of MS was predicted with sensitivity 83.3% (CI:51.6%-98.0%), specificity 85.7% (CI:84.0%-87.2%), and AUC 0.922 (CI:0.858-0.987). None of the MS-recordings had diastolic murmurs, despite the characteristic MS-murmur occurring during diastole. 7 of the total 13 cases (53.9%) of MS also had moderate to severe AS, indicating a considerable disease overlap. Of the 10 detected MS-cases, 4 had no presence of AS, and 3 were not associated with any other VHD (excluding trace and mild levels of AR and MR, which were common in the dataset).\n\nMild or greater AS was predicted by the multi-position model with AUC 0.979 (CI:0.963-0.995), sensitivity 90.9% (CI:78.3-97.5%) and specificity 94.5% (CI:93.3-95.5%), whereas moderate to severe AS was predicted with AUC 0.993 (CI:0.972-0.996). By comparison, maximum (predicted) murmur-grade predicted mild or greater AS with AUC 0.972, and moderate or greater AS with AUC 0.991. Accuracy was in general higher for more severe AS, as can be seen in Table 2, or in Figure 6 which shows AUC as a function of AVPGmean cutoff threshold. A positive test using the multi-position model increased the risk of mild or greater AS from 2.12% to 19.1% (assuming a general population of individuals aged 40 or higher). For moderate to severe AS, the corresponding values were 1.27% and 17.1%. A negative result was estimated to rule out presence of AS with >99% probability. \n\nThe pulmonic position was the position that produced the most accurate prediction of both at least mild and at least moderate AS (see Table 2 which shows prediction performance associated with each position), with an associated AUC value of 0.982 (\u00b10.010) for detection of mild or greater AS. In contrast, prediction based on the aortic position achieved a lower AUC of 0.967, although the difference was not significant (p=0.16). Screening for mild or greater AS on the holdout set using the multi-position model, all 6 cases were detected, the specificity was 90.6%, and the AUC was 0.988.\n\nUsing the multi-position model to predict at least mild AS resulted in 4 missed cases (of 45 cases), of which 3 were mild, and one was moderate (AVPGmean = 27.17 mm Hg). There were 102 false positive predictions, but 20.1% of these observations had AVPGmean>10 mm Hg, which may be of clinical interest despite falling below the set threshold.\n",
        "role": "system"
    },
    {
        "content": "Conversation summary: The user asked about the accuracy of aortic stenosis (AS) prediction based on the threshold used in a machine learning study on predicting valvular heart diseases. The assistant explained that the model was notably reliable with AS severity-moderated accuracy. Mild to severe AS saw an area-under-the-curve (AUC) of 0.979, improving to 0.993 for moderate or more severe cases. The pulmonic position was the most reliable for predicting AS. A multi-position model also accurately predicted AS, albeit with a few misses and false positives. The algorithm was less effective for moderate to severe aortic regurgitation (AR) or mitral regurgitation (MR), except in symptomatic patients, where detectability improved.",
        "role": "system"
    },
    {
        "content": "\u00a4:request_knowledge{hs-paper/results_joint_screening_for_clinically_relevant_cases}:\u00a4",
        "role": "assistant"
    }
]