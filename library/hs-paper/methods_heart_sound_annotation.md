Due to the challenges posed by the low number of VHD cases in the study cohort, our approach involved training a deep learning model to predict murmur grade, which would then serve as a proxy target for predicting VHD. A comparison between models trained on VHD and murmur grade can be found in the Supplementary Materials.

The heart sound recordings were annotated by two General Practitioners (GPs), AD and SA, who were both involved in PhD projects related to heart sounds. AD is a GP specialist with two years of training in cardiology. Before annotation, these two GPs, along with a professor of cardiology (HS) and a professor of General practice (HM), independently annotated 400 recordings. They discussed any disagreements and reached a consensus on the presence and quality of murmurs. This training process continued at intervals throughout the annotation process, where disagreements were discussed to achieve a consensus on the presence of murmurs. The consensus outcomes, to which HM and HS also contributed, are not discussed in this paper. The annotators reviewed spectrogram visualizations of the recordings using Adobe Audition CS6 while classifying the heart sounds. Importantly, they were unaware of the echocardiography results and other information about the study participants during the heart sound annotation.

Each recording was categorized as either normal, systolic murmur, diastolic murmur, or noise (indicating inability to determine the presence of a murmur due to interference or low quality). Any perceived murmurs were graded on a scale from 1 (faint) to 6 (distinct), referencing the Levine scale, commonly used in clinical practice. However, grades 4-6 on this scale are associated with a palpable thrill, which is not directly transferable to recordings. In the annotated set, grades higher than 3 only reflect increases in murmur loudness, not other aspects associated with the Levine scale. In total, 2,129 participants were annotated with both murmur grade and VHD grade. Five were removed due to corrupted audio files, resulting in an effective sample of 2,124 participants and 8,496 annotated audio files (equivalent to 1,416 minutes of audio). The algorithm was trained only on recordings for which both annotators agreed they were not noisy (hereafter referred to as non-noisy recordings). There were 129 (6.1%), 113 (5.3%), 60 (2.8%), and 150 (7.1%) noisy recordings in positions 1 to 4, respectively. 1.4% of participants had noise in all four recordings, and they were excluded from the analysis. For single-recording based prediction, only non-noisy recordings were used. In the case of predictions based on several recordings, noisy recordings were assigned grade 0 (indicating the absence of a murmur).

To represent the murmur grade of each position, we used the average of the two annotators' gradings. In the following, this variable is referred to simply as murmur grade. By this convention, the dataset contained 465, 280, 303, and 196 cases of murmur grade > 0 in positions 1-4, respectively, and a total of 1,244 audio recordings for which at least one annotator perceived a murmur.