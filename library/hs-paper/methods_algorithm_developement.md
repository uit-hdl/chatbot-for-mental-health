The murmur detection algorithm was trained using HS recordings from all four auscultation positions indiscriminately. Network training and prediction was performed in Matlab using the Matlab deep learning toolbox. The model and data processing used in this study are based on a study by Latif et al., in which state of the art results were achieved for detecting abnormal heart sounds on the physionet 2016 challenge dataset. For network architecture we used a 2-layer (50 neurons each) long-short-term-memory (LSTM) network, followed by a fully connected layer consisting of 30 neurons (Figure S1 shows the model architecture) which finally connects to a regression layer which predicts murmur-grade. See the Supplementary Materials for a performance comparison between models trained using binary and continuous labels respectively. The initial learning rate was set to 0.002, and was halved every 5 epochs. To balance the ratio of murmur to non-murmur samples, we dichotomized the data into murmur-grade≥1 and murmur-grade<1, and resampled until the ratio between these classes was approximately one-to-one.

After performing spike removal (following the steps outlined in a 2009 paper by Schmidt et. al.30) and downsampling the signal to sampling rate of 2205 Hz, each recording was segmented into 6 overlapping (50%) blocks, each consisting of 4 cardiac cycles (each cycle starting and ending at the start of the first heart sound, S1). Detection of cardiac cycle boundaries was achieved using a modified version of the segmentation algorithm of Springer et al31,32 that utilizes information from multiple recordings in order to obtain a more robust heart-rate estimate (detailed descriptions of the modifications can be found in the Supplementary Materials). For each segment, the 13 first Mel frequency cepstral coefficients (MFCC) were computed, where we used the Hanning window function with step size of 25 ms and window overlap of 10 ms for computation of the spectrogram. The input units to the LSTM network were finally obtained by resizing the MFCC matrix to dimensions 13×200 using cubic interpolation, followed by subtracting the mean and dividing by the standard deviation of the matrix. The median of the predicted murmur-grades of the 6 blocks was used to represent the prediction for the whole audio recording. Figure S2 provides a schematic overview of the steps that convert raw audio input to algorithm prediction.
